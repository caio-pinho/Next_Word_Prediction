{
  "nbformat": 4,
  "nbformat_minor": 2,
  "metadata": {
    "colab": {
      "name": "Next Word Prediction with Transformers.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3.9.6 64-bit"
    },
    "language_info": {
      "name": "python",
      "version": "3.9.6",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "interpreter": {
      "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "source": [
        "!pip3 install transformers"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33mDEPRECATION: Configuring installation scheme with distutils config files is deprecated and will no longer work in the near future. If you are using a Homebrew or Linuxbrew Python, please see discussion at https://github.com/Homebrew/homebrew-core/issues/76621\u001b[0m\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.9/site-packages (4.9.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.9/site-packages (from transformers) (2.26.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.9/site-packages (from transformers) (2021.8.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.9/site-packages (from transformers) (4.61.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.9/site-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.9/site-packages (from transformers) (5.4.1)\n",
            "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.9/site-packages (from transformers) (0.10.3)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.9/site-packages (from transformers) (0.0.45)\n",
            "Requirement already satisfied: huggingface-hub==0.0.12 in /usr/local/lib/python3.9/site-packages (from transformers) (0.0.12)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.9/site-packages (from transformers) (21.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.9/site-packages (from transformers) (1.21.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.9/site-packages (from huggingface-hub==0.0.12->transformers) (3.10.0.0)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.9/site-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/site-packages (from requests->transformers) (2021.5.30)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/site-packages (from requests->transformers) (3.2)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/site-packages (from requests->transformers) (2.0.3)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/site-packages (from requests->transformers) (1.26.6)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.9/site-packages (from sacremoses->transformers) (1.16.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.9/site-packages (from sacremoses->transformers) (1.0.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.9/site-packages (from sacremoses->transformers) (7.1.2)\n",
            "\u001b[33mWARNING: You are using pip version 21.2.3; however, version 21.2.4 is available.\n",
            "You should consider upgrading via the '/usr/local/opt/python@3.9/bin/python3.9 -m pip install --upgrade pip' command.\u001b[0m\n"
          ]
        }
      ],
      "metadata": {
        "id": "RNu1tMQEo4kO"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "source": [
        "import torch\n",
        "import string\n",
        "from transformers import BertTokenizer, BertForMaskedLM"
      ],
      "outputs": [],
      "metadata": {
        "id": "mlM21EOGorIF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "source": [
        "bert_model = BertForMaskedLM.from_pretrained('neuralmind/bert-base-portuguese-cased').eval()\n",
        "bert_tokenizer = BertTokenizer.from_pretrained('neuralmind/bert-base-portuguese-cased', do_lower_case=False)\n",
        "\n",
        "top_k = 10\n",
        "\n",
        "def encode(tokenizer, text_sentence, add_special_tokens=True):\n",
        "    text_sentence = text_sentence.replace('<mask>', tokenizer.mask_token)\n",
        "    # se <mask> for o último token, acrescenta um \".\" (ponto) porque que os modelos não prever pontuação.\n",
        "    if tokenizer.mask_token == text_sentence.split()[-1]:\n",
        "        text_sentence += ' .'\n",
        "\n",
        "    input_ids = torch.tensor([tokenizer.encode(text_sentence, add_special_tokens=add_special_tokens)])\n",
        "    mask_idx = torch.where(input_ids == tokenizer.mask_token_id)[1].tolist()[0]\n",
        "    return input_ids, mask_idx\n",
        "\n",
        "def decode(tokenizer, pred_idx, top_clean):\n",
        "    ignore_tokens = string.punctuation + '[PAD]'\n",
        "    tokens = []\n",
        "    for w in pred_idx:\n",
        "        token = ''.join(tokenizer.decode(w).split())\n",
        "        if token not in ignore_tokens:\n",
        "            tokens.append(token.replace('##', ''))\n",
        "    return '\\n'.join(tokens[:top_clean])\n",
        "\n",
        "def get_all_predictions(text_sentence, top_clean):\n",
        "    input_ids, mask_idx = encode(bert_tokenizer, text_sentence)\n",
        "    #print('Input: ', input_ids)\n",
        "    #print('Mask: ', mask_idx)\n",
        "  \n",
        "    with torch.no_grad():\n",
        "        predict = bert_model(input_ids)[0]\n",
        "    bert = decode(bert_tokenizer, predict[0, mask_idx, :].topk(top_k).indices.tolist(), top_clean)\n",
        "    return bert"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at neuralmind/bert-base-portuguese-cased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
            "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H7Nw9iDroyS-",
        "outputId": "25851379-4b50-40ba-f14b-f86e7b87d11d"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "source": [
        "def get_predictions(input_text, best_n_predictions=1):\n",
        "    try:\n",
        "        input_text += ' <mask>'\n",
        "        res = get_all_predictions(input_text, best_n_predictions)\n",
        "        return res\n",
        "\n",
        "    except Exception as error:\n",
        "        err = str(error)\n",
        "        return err"
      ],
      "outputs": [],
      "metadata": {
        "id": "9m_pvUw4qTxq"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "source": [
        "input_text = \"Dinheiro não traz\"\n",
        "\n",
        "print(get_predictions(input_text,1))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "felicidade\n"
          ]
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7gc-VsUfqsED",
        "outputId": "3501f34a-d54d-4669-a12a-c5d5cd3c1906"
      }
    }
  ]
}